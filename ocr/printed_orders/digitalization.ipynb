{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2d8a740277f67c33143a8e5c8e55f738530a350d8def4a85d8635b690074994c"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Printed orders digitalization\n",
    "\n",
    "TODO\n",
    "- Train tesseract for handwritten digits\n",
    "    - https://stackoverflow.com/questions/10763017/training-tesseract-for-handwritten-text\n",
    "    - https://tesseract-ocr.github.io/tessdoc/Training-Tesseract\n",
    "- Finish reading:\n",
    "    - https://tesseract-ocr.github.io/tessdoc/ImproveQuality\n",
    "    - https://medium.com/better-programming/beginners-guide-to-tesseract-ocr-using-python-10ecbb426c3d\n",
    "\n",
    "## Requirements\n",
    "- [tesseract-ocr](https://github.com/tesseract-ocr/tesseract)\n",
    "- [Spanish trained data for tesseract](https://github.com/tesseract-ocr/tessdata_best/blob/master/spa.traineddata)\n",
    "- [pytesseract](https://pypi.org/project/pytesseract/)\n",
    "- [opencv-python](https://pypi.org/project/opencv-python/)\n",
    "- [matplotlib](https://matplotlib.org/)\n",
    "- [numpy](https://numpy.org/install/)\n",
    "- [scipy](https://www.scipy.org/)\n",
    "- [enchant](https://abiword.github.io/enchant/)\n",
    "\n",
    "## Resources"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Imports\n",
    "\n",
    "Load the required libraries"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "import string\n",
    "\n",
    "import cv2\n",
    "import enchant\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import ndimage"
   ]
  },
  {
   "source": [
    "### Preprocessing\n",
    "\n",
    "Transform the image"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "def get_image(filename):\n",
    "    return cv2.imread(filename)\n",
    "\n",
    "\n",
    "def save_image(folder, filename, image):\n",
    "    print(f'Save image: {folder / filename} | {cv2.imwrite(str(pathlib.Path(\"output\") / filename), image)}')\n",
    "\n",
    "\n",
    "def get_kernel(size):\n",
    "    return np.ones((size, size), np.uint8)\n",
    "\n",
    "\n",
    "def get_gray_image(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "def get_mask(image):\n",
    "    return np.zeros(image.shape, dtype=image.dtype)\n",
    "\n",
    "\n",
    "def get_image_edges(image):\n",
    "    return cv2.Canny(image, 175, 175)\n",
    "\n",
    "\n",
    "def get_angle(image):\n",
    "    image_edges = get_image_edges(image)\n",
    "    lines = cv2.HoughLinesP(image_edges, 1, math.pi / 180, 100, minLineLength=100, maxLineGap=5)\n",
    "    angles = []\n",
    "    for [[x1, y1, x2, y2]] in lines:\n",
    "        angles.append(math.degrees(math.atan2(y2 - y1, x2 - x1)))\n",
    "    return np.median(angles)\n",
    "\n",
    "\n",
    "def get_rotated_image(image, angle):\n",
    "    if angle:\n",
    "        return ndimage.rotate(image, angle)\n",
    "    return image\n",
    "\n",
    "\n",
    "def get_thresholded_image(binary_image):\n",
    "    return cv2.adaptiveThreshold(binary_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 25, 11)\n",
    "\n",
    "\n",
    "def get_blurred_image(image, kernel):\n",
    "    return cv2.blur(image, kernel.shape)\n",
    "\n",
    "\n",
    "def get_denoised_image(image):\n",
    "    return cv2.fastNlMeansDenoising(image, 5)\n",
    "\n",
    "\n",
    "def get_eroded_image(image, kernel):\n",
    "    return cv2.erode(image, kernel)\n",
    "\n",
    "\n",
    "def get_dilated_image(image, kernel):\n",
    "    return cv2.dilate(image, kernel)\n",
    "\n",
    "\n",
    "def get_biggest_contour(contours):\n",
    "    return max(contours, key=lambda x: cv2.contourArea(x))\n",
    "\n",
    "\n",
    "def draw_contours(image, contours, thickness=10):\n",
    "    image = np.copy(image)\n",
    "    return cv2.drawContours(image, contours, -1, (255, 255, 255), thickness)\n",
    "\n",
    "\n",
    "def set_color(gray_image, thresh, color):\n",
    "    color = np.full_like(gray_image, (color,))\n",
    "    return np.where(thresh!=0, gray_image, color)\n",
    "\n",
    "\n",
    "def get_print_contour(image_gray, kernel):\n",
    "    eroded_image = get_dilated_image(image_gray, kernel)\n",
    "    contours = cv2.findContours(cv2.bitwise_not(eroded_image), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "    return get_biggest_contour(contours)\n",
    "\n",
    "\n",
    "def get_mask_contourned(mask, contours):\n",
    "    return draw_contours(mask, contours, -1)\n",
    "\n",
    "\n",
    "def get_masked_image(image, mask):\n",
    "    # Apply mask over an image\n",
    "    return cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "\n",
    "def get_kmeans_transformed_image(image):\n",
    "    data = np.float32(image.reshape((-1,3)))\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 4, 1)\n",
    "    label, center = cv2.kmeans(data, 8, None, criteria, 4, cv2.KMEANS_RANDOM_CENTERS)[1:]\n",
    "    center = np.uint8(center)\n",
    "    return center[label.flatten()].reshape((image.shape))\n",
    "\n",
    "\n",
    "def get_recorted_image(image, contour):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    return image[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "def get_horizontal_lines_structure(image):\n",
    "    cols = image.shape[1]\n",
    "    horizontal_size = cols // 30\n",
    "    return cv2.getStructuringElement(cv2.MORPH_RECT, (horizontal_size, 1))\n",
    "\n",
    "\n",
    "def get_vertical_lines_structure(image):\n",
    "    rows = image.shape[0]\n",
    "    vertical_size = rows // 30\n",
    "    return cv2.getStructuringElement(cv2.MORPH_RECT, (1, vertical_size))\n",
    "\n",
    "\n",
    "def get_structure_contours(negative_gray_image, structure):\n",
    "    eroded_image = get_eroded_image(negative_gray_image, structure)\n",
    "    return cv2.findContours(eroded_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)[0]\n",
    "\n",
    "\n",
    "def remove_print_lines(image_gray):\n",
    "    # remove cell boxs\n",
    "    bw = cv2.bitwise_not(image_gray)\n",
    "    contours = []\n",
    "    horizontal_lines_structure = get_horizontal_lines_structure(bw)\n",
    "    contours.append(get_structure_contours(bw, horizontal_lines_structure))\n",
    "    vertical_lines_structure = get_vertical_lines_structure(bw)\n",
    "    contours.append(get_structure_contours(bw, vertical_lines_structure))\n",
    "    return np.concatenate([\n",
    "        np.array(contour, dtype=\"object\")\n",
    "        for contour in contours\n",
    "    ])"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "### Text Detection\n",
    "\n",
    "Mark the detected text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_detected_text(image, tesseract_config):\n",
    "    return pytesseract.image_to_data(image, **tesseract_config)\n",
    "\n",
    "\n",
    "def get_image_with_detected_text(image, data):\n",
    "    image = np.copy(image)\n",
    "    for i in range(len(data['level'])):\n",
    "        x, y, w, h = data['left'][i], data['top'][i], data['width'][i], data['height'][i]\n",
    "        image = cv2.rectangle(image, (x - 1, y - 1), (x + w + 2, y + h + 2), (0, 0, 255), 2)\n",
    "    return image"
   ]
  },
  {
   "source": [
    "### Text Recognition\n",
    "\n",
    "Recognize the text"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recognized_text(image, tesseract_config):\n",
    "    recognized_text = pytesseract.image_to_string(image, **tesseract_config)\n",
    "    return '\\n'.join(line for line in recognized_text['text'].rsplit('\\n') if line.strip())\n",
    "\n",
    "\n",
    "def get_allowed_characters(dictionary):\n",
    "    # Get allowed characters based on a dictionary.\n",
    "    # Also add basics number characters, as the dot and the digits.\n",
    "    with open(dictionary, encoding='utf-8') as f:\n",
    "        return set(string.digits) | set(f.read()) | {'.'}\n",
    "\n",
    "\n",
    "def replace_characters(text, characters_tuple):\n",
    "    for character_tuple in characters_tuple:\n",
    "        text = text.replace(*character_tuple)\n",
    "    return text\n",
    "\n",
    "\n",
    "def remove_not_allowed_characters(text, allowed_characters):\n",
    "    not_allowed_characters = re.compile(f'[^{\"\".join(allowed_characters)}]')\n",
    "    return not_allowed_characters.sub(' ', text)\n",
    "\n",
    "\n",
    "def remove_empty_lines(text):\n",
    "    return '\\n'.join(line for line in text.split('\\n') if line.strip())\n",
    "\n",
    "\n",
    "def get_spell_checker(dictionary):\n",
    "    # Create a spell checker based on a dictionary file.\n",
    "    # The words can be separated by whitespaces.\n",
    "    spell_checker = enchant.PyPWL()\n",
    "    spell_checker.pwl = spell_checker.tag = os.path.abspath(dictionary)\n",
    "    words = set()\n",
    "    with open(dictionary, encoding='utf-8') as f:\n",
    "        words |= set(f.read().split())\n",
    "    for word in words:\n",
    "        spell_checker.add_to_session(word)\n",
    "    return spell_checker\n",
    "\n",
    "\n",
    "def get_converted_string(string):\n",
    "    try:\n",
    "        return int(string)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(string)\n",
    "        except ValueError:\n",
    "            return string\n",
    "\n",
    "\n",
    "def get_corrected_text(spell_checker, text):\n",
    "    # Use spell checker to make corrections to a text\n",
    "    corrected_lines = []\n",
    "    for line in text.upper().split('\\n'):\n",
    "        corrected_words = []\n",
    "        for word in line.split():\n",
    "            converted_word = get_converted_string(word)\n",
    "            # If the string isn't a representation of an int or float,\n",
    "            # it's a word representation and maybe we need to make corrections on them\n",
    "            # using the spell checker.\n",
    "            if isinstance(converted_word, str):\n",
    "                suggestion = spell_checker.suggest(converted_word)\n",
    "                if suggestion:\n",
    "                    corrected_words.append(suggestion[0])\n",
    "                else:\n",
    "                    corrected_words.append(converted_word.upper())\n",
    "            else:\n",
    "                corrected_words.append(str(converted_word))\n",
    "        corrected_lines.append(' '.join(corrected_words))\n",
    "    return '\\n'.join(corrected_lines)"
   ]
  },
  {
   "source": [
    "## Implementation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the basic config\n",
    "filename = 'order.jpg'\n",
    "tesseract_config = {\n",
    "    'config': '--oem 3 --psm 12',\n",
    "    'lang': 'eng+spa',\n",
    "}\n",
    "initial_angle = 0\n",
    "output_folder_name = 'output'\n",
    "dictionary = 'fields.txt'\n",
    "\n",
    "# Run some basic setup\n",
    "tesseract_config['output_type'] = pytesseract.Output.DICT\n",
    "output_folder = pathlib.Path(output_folder_name)\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "image = get_image(filename)\n",
    "image = get_rotated_image(image, initial_angle) "
   ]
  },
  {
   "source": [
    "<p align=\"center\">order.jpg</p>\n",
    "<p align=\"center\"><img align=\"center\" src=\"order.jpg\" width=\"400px\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold\n",
    "thresh = get_thresholded_image(get_gray_image(image))\n",
    "save_image(output_folder, f'thresh.{filename}', thresh)"
   ]
  },
  {
   "source": [
    "<p align=\"center\">thresh.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/thresh.order.jpg\" width=\"400\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the ROI and remove the background\n",
    "mask = get_mask(get_gray_image(image))\n",
    "\n",
    "print_contour = get_print_contour(thresh, get_kernel(1))\n",
    "print_contourned = get_mask_contourned(mask, [print_contour])\n",
    "save_image(output_folder, f'contourned.{filename}', print_contourned)\n",
    "\n",
    "mask_contour = get_print_contour(cv2.bitwise_not(print_contourned), get_kernel(20))\n",
    "mask_contourned = get_mask_contourned(mask, [mask_contour])\n",
    "white_background = set_color(thresh, mask_contourned, 255)\n",
    "save_image(output_folder, f'white-background.{filename}', white_background)\n",
    "\n",
    "recorted_image = get_recorted_image(white_background, print_contour)\n",
    "save_image(output_folder, f'recorted.{filename}', recorted_image)\n",
    "recorted_image_original = get_recorted_image(image, print_contour)\n",
    "save_image(output_folder, f'recorted.original.{filename}', recorted_image_original)"
   ]
  },
  {
   "source": [
    "<p align=\"center\">contourned.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/contourned.order.jpg\" width=\"400\"></p>\n",
    "<br>\n",
    "<p align=\"center\">white-background.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/white-background.order.jpg\" width=\"400\"></p>\n",
    "<br>\n",
    "<p align=\"center\">recorted.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/recorted.order.jpg\" width=\"400\"></p>\n",
    "<br>\n",
    "<p align=\"center\">recorted.original.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/recorted.original.order.jpg\" width=\"400\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deskew\n",
    "angle = get_angle(recorted_image)  # 0.0 for this case\n",
    "image = get_rotated_image(image, angle)\n",
    "image_rotated = get_rotated_image(recorted_image, angle)\n",
    "save_image(output_folder, f'rotated.{filename}', image_rotated)\n",
    "image_rotated_original = get_rotated_image(recorted_image_original, angle)\n",
    "save_image(output_folder, f'rotated.original.{filename}', image_rotated_original)"
   ]
  },
  {
   "source": [
    "<p align=\"center\">rotated.order.jpg</p>\n",
    "<p align=\"center\"><i>(0 rotation for this case)</i></p>\n",
    "<p align=\"center\"><img src=\"output/rotated.order.jpg\" width=\"400\"></p>\n",
    "<br>\n",
    "<p align=\"center\">rotated.original.order.jpg</p>\n",
    "<p align=\"center\"><i>(0 rotation for this case)</i></p>\n",
    "<p align=\"center\"><img src=\"output/rotated.original.order.jpg\" width=\"400\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilate characters\n",
    "dilated = get_dilated_image(image_rotated, get_kernel(2))\n",
    "save_image(output_folder, f'dilated.{filename}', dilated)"
   ]
  },
  {
   "source": [
    "<p align=\"center\">dilated.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/dilated.order.jpg\" width=\"400\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mark the detected text (this step isn't necessary).\n",
    "# The text boxes are marked over the original recorted and rotated image.\n",
    "detected_text = get_detected_text(dilated, tesseract_config)\n",
    "image_with_detected_text = get_image_with_detected_text(image_rotated_original, detected_text)\n",
    "save_image(output_folder, f'detected.{filename}', image_with_detected_text)"
   ]
  },
  {
   "source": [
    "<p align=\"center\">detected.order.jpg</p>\n",
    "<p align=\"center\"><img src=\"output/detected.order.jpg\" width=\"400\"></p>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recognize the text\n",
    "recognized_text = get_recognized_text(dilated, tesseract_config)\n",
    "allowed_characters = get_allowed_characters(dictionary)\n",
    "text = replace_characters(recognized_text, ((',', '.'),))\n",
    "text = remove_not_allowed_characters(text, allowed_characters)\n",
    "text = remove_empty_lines(text)\n",
    "spell_checker = get_spell_checker(dictionary)\n",
    "corrected_text = get_corrected_text(spell_checker, text)\n",
    "print(corrected_text)"
   ]
  },
  {
   "source": [
    "```\n",
    "DIA:\n",
    "HORA:\n",
    "PAN\n",
    "PAN LACTAL\n",
    "5\n",
    "GALLETA\n",
    "PAN LACTAL DE SALVADO\n",
    "CORONITAS\n",
    "PAQ. PAN DE MIGA\n",
    "MIGA\n",
    "C/ TORTA\n",
    "G.\n",
    "PAQ. MIGA SALVADO\n",
    "PAN CHORIPAN\n",
    "HAMB X 4 UNID.\n",
    "HAMBURGUESASX 20\n",
    "PAQ. PERNIL/CHIPS X 6 UNID.\n",
    "TORPEDO\n",
    "VIENAS X 6\n",
    "VIENA LARGO/CORTOS\n",
    "HAMBURGUESAS X 4\n",
    "PAN DE LOMO CUADR BOLSA\n",
    "LOMO X 2\n",
    "PAN PERNIL\n",
    "G.\n",
    "ITALIANOS\n",
    "G.\n",
    "MEDIALUNAS SALADAS\n",
    "30\n",
    "G. COMUNES\n",
    "MEDIALUNAS DULCES\n",
    "G.\n",
    "G. CHATOS SABORIZ.\n",
    "FACTURAS GRANDES\n",
    "GRISINES C/SEMILLA\n",
    "FACTURAS C/DULCE\n",
    "GRISINES SALVADO\n",
    "FACTURAS HOJALDRE\n",
    "GALLETITAS C/SEMILLA\n",
    "TOSTADAS\n",
    "VIGILANTES\n",
    "SACRAMENTOS\n",
    "BIZCOCHOS SALVADO\n",
    "MINIFACTURITAS\n",
    "PREPIZZA\n",
    "DONAS\n",
    "PREPIZZA CHICA\n",
    "TARTELETAS\n",
    "ENTERO SALVADO\n",
    "BIZCOCHOS DULCES\n",
    "ENTERO BLANCO\n",
    "TORTA BIZCOCHUELO\n",
    "BIZCOCHOS MEMBRILLO\n",
    "BIZCOCHO CREMA PASTELERA\n",
    "TORTA MIXTA\n",
    "BIZC BATATA\n",
    "TORTA HOJALDRE\n",
    "BIZC CRIOLLITOS\n",
    "TORTA PORCION\n",
    "BIZC CASERITOS\n",
    "MASAS FINAS\n",
    "CUPCAKES\n",
    "BIZC AGUA\n",
    "BIZC SALADO HOJALDRE\n",
    "MAGDALENAS\n",
    "BUDINES\n",
    "X\n",
    "120 C/QUESO\n",
    "BIZC CHICHA\n",
    "MADRIL GRANDES\n",
    "PAN DULCE\n",
    "MADRIL MEDIANOS\n",
    "SANTAFESINOS\n",
    "PANETTON\n",
    "MAIZENAS CHICOS\n",
    "PALMERITAS\n",
    "MASITAS SABORIZADAS\n",
    "DEVOLUCIONES:\n",
    "MERENGUES CHICOS\n",
    "MERENG.C/ DULCE/CREMA\n",
    "CAÃ‘ONCITOS C/DULCE\n",
    "PASTA FROLA GRANDES\n",
    "PASTA FROLA CHICA\n",
    "```"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}